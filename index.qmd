---
title: "Exploration of Different Imputation Methods for Missing Data"
author: "Karthik Aerra, Liz Miller, Mohit Kumar Veeraboina, Robert Stairs"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction

Missing data is a key challenge that data professionals encounter in their daily work. In the real world, data is often messy, incomplete, and requires a level of pre-processing before data analysis can occur. Part of data pre-processing is dealing with missing data. Missing data can occur for several reasons including but not limited to processing error, machine or measurement errors, non-responses in surveys, invalid calculations (e.g. division by zero), and study participant dropout [@Emmanuel2021surveyml]. Missing data can be problematic for analysis because it can reduce the number of usable observations, introduce bias, and interfere with different analysis tools such as machine learning algorithms, which cannot automatically handle missing data.

One of the first steps in handling missing data is to determine how much of the data is missing and from which columns. Missing data in a dataset can be represented in several ways including NA, NaN, Null, None, blanks, spaces, empty strings, or placeholder values such as 999999 (or equivalent obvious numerical outlier). For standard missing values such as NAs, functions such as is.na() in R can be used to count the number of missing observations. For string-related missing values such as space (“ ” or empty strings (“”), functions such as unique() in R can be used to identify unexpected strings. For numerical placeholders such as 0, 99999 (or equivalent), or negative values, histograms of the data can be useful to identify missing values.

If a dataset contains missing data, there are two basic approaches: deletion or imputation [@schefer2002dealingwithmissingdata]. Deletion of data can be problematic for analysis, especially when the proportion of missing data is high or the overall number of observations is low. Deletion of data can also lead to bias or understimation of variance if the data are not missing completely at random. It is crucial when choosing an approach to missing data that the underlying mechanism(s) for the missing data are understood. 

The mechanisms for missing data can generally be broken up into three categories [@mack2018managing], [@may2009modelling], [@bennett2001can], [@little2014joys], [@du2020missing]:

**Missing completely at random (MCAR)**
When data are MCAR, the probability of a record missing is independent from observed and unobserved data. For example, if performing a survey with age as a variable, missing values for age are random with respect to age and do not depend on other variables such as weight or gender. In the case of MCAR data, the deletion of data reduces the number of observations in the dataset but does not introduce bias. MCAR is the most ideal, but least realistic scenario.

**Missing at Random (MAR)**
When data are MAR, the probability of a record missing depends on the observed data, but not the unobserved data. Using the same example of a survey with age as a variable, people who are overweight may be more likely to omit their age in the survey. However, the probability of a missing data point can be attributed to another observed variable. In the case of MAR, deletion of entire observations with missing data may or may not introduce bias.

**Not missing at random (NMAR)**
When data are NMAR, the probability of a record missing is dependent on the unobserved data. In the same example of a survey including age as a variable, elderly people may be less likely to include their age in the survey. The missing value for age cannot be predicted using other variables included in the dataset such as weight or gender. There may be a factor that can predict the probability of a missing value, but it is unknown. NMAR data are the most complicated to analyze. Similarly to MAR, deletion of observations with missing data may or may not introduce bias to the analysis.

![MCAR, MAR, and NMAR Example, [@du2020missing]](Missing Data Mechanisms Figure.png)

Understanding the mechanism behind missing data (MCAR, MAR, or NMAR) is important because many imputation methods require the assumption of MCAR or MAR to be held true. There is not a statistical test or analysis to classify data as MCAR, MAR, or NMAR. Instead, visualization of the missing data is required to determine the relationships (or lack thereof) within the missing data. For example, correlation matrix plots, scatterplots, and other custom visualizations can be useful tools in identifying patterns in the missing data [@ghazali2020missing]. 

Methods for handling missing data can be split into three broad categories [@ren2023review], [@Emmanuel2021surveyml]:

* **Deletion methods**
* One of the approaches to handling missing data is to delete instances of missing values. This can be accomplished through either listwise deletion or pairwise deletion, for example. In listwise deletion, all rows with missing values are deleted from the dataset. This results in a dataset with a lower number of observations. In pairwise deletion, columns with missing data are deleted from the dataset. In this way, the number of observations in the dataset is maintained, but the total number of features is reduced. Deletion methods are advantageous in that they are quick and simple. With a large dataset and relatively low amounts of missing data, reducing the number of observations or features may be okay. However, deletion can introduce bias into the analysis if the data are not missing completely at random, which is often the case [@ren2023review], [@Emmanuel2021surveyml].

* **Single imputation**
* In single imputation, missing data values are replaced with a single value, without consideration of the uncertainty around the prediction for the missing value. In other words, a single value is predicted for each missing data point. This can be accomplished using techniques such as mean imputation, median imputation, hot and cold deck imputation and regression-based techniques. There is not a model defined for predicting the values in the column as a whole, so there is information lost around the variance of the prediction. Single imputation methods are simpler than multiple imputation methods, but they tend to underestimate the variance resulting models may have artifically low confidence intervals [@ren2023review], [@Emmanuel2021surveyml].


* **Multiple imputation**
* In multiple imputation methods such as MICE, a model is constructed to predict missing values in each column based on observed data in other columns. This model provides a point estimate for the missing values, as well as the uncertainty around the predictions. Multiple iterations are performed to predict the missing values. In each iteration, a missing value is predicted based on the model and its uncertainty. That is, with multiple iterations, you will end up with a distribution of possible missing values. In this way, multiple datasets with multiple possible values for the missing data are generated. Once the iterations are complete, the missing data predictions can consolidated back into a single dataset, where the missing values will be a result of the point estimate and the variance or uncertainty from the model. Multiple imputation can be a powerful technique that is helpful in preserving some of the variance or uncertainty around missing values, but it can be complex and computationally expensive. [@ren2023review], [@Emmanuel2021surveyml]. 


Imputation methods can be further broken down into statistical versus machine learning methods. According to [@lin2020missing]'s review of literature from 2006-2017, four of the most common statistical methods for missing value imputation include expectation management (EM), linear regression, least squares (LS), and mean/mode imputation. For machine learning, the four most common methods include clustering, decision trees, random forest, and KNN.


**Theories**

**Rubin's Missing Data Theory:** 
This foundational theory categorizes missing data into MCAR, MAR, and NMAR. It provides a framework for understanding the mechanisms behind missing data and guides the selection of appropriate imputation strategies based on these mechanisms. (**CITATION NEEDED**) 

**Statistical Theory of Imputation:**
This theory involves using statistical models to estimate missing values, leveraging the relationship between observed and missing data points. Multiple imputation, a prominent technique within this theory, generates multiple plausible values for each missing data point to account for uncertainty. (**CITATION NEEDED**) 

**Machine Learning Theories:**
Machine learning techniques are increasingly employed for imputing missing data due to their ability to learn patterns from data and make predictions. Methods such as k-nearest neighbors (KNN) and neural networks are applied to predict missing values based on observed data patterns. (**CITATION NEEDED**) 

These theories provide a comprehensive framework for understanding and implementing imputation methods across various datasets and analytical contexts.

**Research Methods for Missing Data:**

**Descriptive Studies:** These studies analyze the patterns of missing data and evaluate the effectiveness of various imputation methods. Examples include the work by Jerez et al. and Güzel [@jerez2010statisticalandmlmethods], [@guzel2013knn].

**Comparative Studies:** These studies compare the performance of different imputation methods. Joseph G. Ibrahim and Siming Zheng have conducted such comparative analyses, highlighting the strengths and weaknesses of various approaches [@ibrahim2011glm], [@zhang2024matrixcompletionmethod], [@zheng2023likelihood].

**Simulation Studies:** These studies test imputation methods on controlled datasets, allowing researchers to systematically observe the impact of different techniques. This helps in understanding the conditions under which each method performs best.

**Application-Based Studies:** These studies apply imputation methods to real-world data, demonstrating their practical use and the challenges involved. Examples include the works by Saqib Ejaz Awan and Emmanuel, which show how imputation methods are implemented in practical scenarios [@awan2022reinforcementlearning], [@Emmanuel2021surveyml].

**Theoretical Analysis:** This involves discussing the conditions, limitations, and best practices of imputation methods. Rachael A Hughes' work is an example, providing insights into when multiple imputation is not suitable and suggesting alternative approaches.

The purpose of this project is to demonstrate the use of several different types of missing data imputation methods using a test dataset with missing data. The performance of various imputation methods will be assessed using RMSE and R-Squared of the resulting predictive models after applying various imputation methods.


### Related work



## Methods

**Literature Research**

The approach used to select and analyze the literature included in this review involved identifying articles relevant to the topic of missing data and the imputation thereof.  Articles were selected based on their topic relevance as it related to statistical and machine learning concepts.  Preference was given to articles that were published recently to ensure the inclusion of the latest methods and research in the field.  In addition, articles were prioritized from peer-reviewed and reputable conference papers to ensure quality and reliability of the research.  A comprehensive search using Google Scholar and the available databases accessed through the University of West Florida was implemented.  Key search terms included: ‘missing data’, ‘missing data imputation’.

Articles were selected based on their relevance to the subject, in addition to including papers with a variety of methods implemented. Research addressing both statistical and machine learning approaches were focused on.  Articles not available in full text, not directly related to missing data imputation methods, or where the primary focus was theoretical as opposed to practical were excluded. Once an article was selected, it was reviewed for relevant data pertaining to missing data imputation methods. The context of the study, the datasets involved, and the results provided were also reviewed. The article analysis focused on:


* **Goal** – understanding the specific goal of the study and how it relates to missing data imputation.
* **Methods/Techniques** – Identifying the specific methods used, whether statistical or machine learning, or a combination of both.
* **Results/Applications** – evaluating the effectiveness/efficiency of the methods employed. Showing how these methods were/can be applied in a real-world scenario.
* **Limitations/Challenges** – noting the limitations or challenges involved in each method used.
* **Data** – identifying the types of data used for testing (e.g. simulated, real-world) and the type of missing data (e.g. missing at random, missing completely at random, not missing at random) 

**Data Analysis Methodology**

An overview of the methodology used to demonstrate different techniques for imputing missing data is shown below:

![Overivew of Methodology for Demonstrating Different Techniques for Missing Data Imputation](MIssing Data Workflow Graphic.png)

!(MIssing Data Workflow Graphic.png)

To demonstrate the use of different imputation techniques for handling missing data, a dataset was selected with a high frequency of missing data. The "Ozone" dataset from the mlbench package, which contains ~38% missing values for one of the variables was selected for this case study. The data were first pre-processed. This step typically entails importing the data, checking for missing values, checking data types, and making transformations as needed. In this case, all columns were converted to numeric data type and renamed for easier interpretation. Missing values by column were reported in summary statistics, but were not addressed until further visualization was performed.

Following pre-processing, correlation coefficients were calculated for all variables with respect to Ozone levels (the response variable). Variables with strong positive or negative correlation were then visualized using histograms to show the distribution of each variable with respect to percentage of Ozone level readings. Missing data were then visualized to determine if there were any significant patterns to the missingness of the data. The purpose of this step is to provide evidence to support that the data are either MCAR, MAR, or MNAR.

Once the missing mechanism was established, the missing data were imputed using one of the following methods:

*  **Mean imputation**
* In mean imputation, missing values for a given column are all replaced with a single value: the mean of the non-missing values.

* **Mode imputation**
* In mode imputation, missing values for a given column are all replaced with a single value: the mode of the non-missing values.

* **Median imputation**
* In median imputation, missing values for a given column are all replaced with a single value: the median of the non-missing values.

* **MICE (multiple imputation by chained equations)**
* In MICE, missing data for a given column are imputed based on other columns with observed data over multiple iterations [@azur2011multiple]. It operates under the assumption that the data are missing at random (MAR). For a missing column, the missing values are imputed using regression based on observed data from other columns in the dataset. Then, the next column's missing data are imputed using observed data in other columns and so forth until regression models are available for each column. Each regression model will have its own level of uncertainty. With each iteration, a possible missing value is imputed for a given data point given the regression function and its associated uncertainty. This process is repeated over multiple iterations, where the number of iterations is set by the user. This results in multiple datasets, which are then combined into a single dataset again. In this case, 50 iterations were used.

* **Random Forest**
* Random forest is an ensemble machine learning method, where the data set is bootstrap sampled randomly and individual decision trees are constructed for each bootstrap [@tang2017random]. The collection of decision trees is then used to impute a missing data point. This technique in machine learning helps prevent overfitting that decision trees are prone to.

Once missing values were imputed using each of the five methods outlined above, each resulting dataset (5) was used to fit models for Ozone levels. The datasets were split into training and test sets using a split ratio of 0.75. The following models were then used for training each dataset:

* Decision Tree
* Random Forest
* KNN
* SVM

The effectiveness of each imputation technique was evaluated using RMSE and R-Squared for the resulting Ozone level models. The RMSE and R-Squared for each imputation/model combination were reported and summarized in a data frame. The combination with the lowest RMSE was determined to be the most effective imputation technique and model fit for this dataset.



## Analysis and Results

**Description of the Dataset**

The “Ozone: Los Angeles Ozone Pollution Data, 1976” dataset has been chosen for this project. It contains observations related to pollution levels in the Los Angeles area during 1976. The variables contained in the dataset are thought to influence ozone concentration. These include daily ozone measurements consisting of: 

* V1: Month, 1-12, where 1 is January and 12 is December
* V2: Day of month
* V3: Day of week, 1-7, where 1 is Monday and 7 is Sunday
* V4:	Daily maximum one-hour-average ozone reading
* V5: 500 millibar pressure height (m) measured at Vandenberg AFB
* V6:	Wind speed (mph) at  Los Angeles International Airport (LAX)
* V7:	Humidity (%) at LAX
* V8:	Temperature (degrees F) measured at Sandburg, CA
* V9:	Temperature (degrees F) measured at El Monte, CA
* V10: Inversion base height (feet) at LAX
* V11: Pressure gradient (mm Hg) from LAX to Daggett, CA
* V12: Inversion base temperature (degrees F) at LAX
* V13: Visibility (miles) measured at LAX

The dataset allows for analysis of how different meteorological conditions/factors can affect ozone levels. It contains a total of 13 variables, 366 observations (one for each day for one year), and 139 missing or NA values for V9, which we will attempt to impute with the method chosen.

**Load Packages**

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 

library(mlbench)
library(dplyr)
library(ggplot2)
library(vtable)
library(knitr)
library(kableExtra)
library(tidyverse)
library(tidyr)
library(naniar)
library(ggplot2)
library(UpSetR)
library(corrplot)
library(gridExtra)
library(reshape2)
library(ggpubr)
library(caTools)
library(party)
library(magrittr)
library(ggfittext)


```


**Importing and Summarizing the Data**

First, the data were imported and converted to a data frame. Next, columns were reordered such that V4 (response variable) is the first column. Lastly, the data were summarized using the summary() function. The summary function gives the number of NA's per column. There are 139 missing values for V9 in the dataset. The number of missing values (NA's) in each column are as follows:

* V4: 5
* V1: None
* V2: None
* V3: None
* V5: 12
* V6: None
* V7: 15
* V8: 2
* **V9: 139**
* V10: 15
* V11: 1
* V12: 14
* V13: None

```{r, warning=FALSE, echo=TRUE}

# Import data
data("Ozone", package = "mlbench")

# Cconvert to data frame
ozone1 <- data.frame(Ozone)

# Reorder columns
ozone1 <- ozone1 %>%
  dplyr::select(V4,V1,V2,V3,V5,V6,V7,V8,V9,V10,V11,V12,V13)

# View summary of data
summary(ozone1)


```

**Data Pre-Processing**

First, the data type was evaluated for each column. V1, V2, and V3 (Month, day of month, and day of week) were found to be "factor" data type, while the remaining columns were found to be be "numeric". V1, V2, and V3 columns were converted to numeric data type.

```{r, warning=FALSE, echo=T, message=FALSE}

# Create function to check data types of data frame columns
check_data_types <- function(ozone1) {
  sapply(ozone1, class)
}

# Check data types of the columns
data_types <- check_data_types(ozone1)
print(data_types)


# Function to convert specified columns from factor to numeric
convert_factors_to_numeric <- function(data, columns) {
  data[columns] <- lapply(data[columns], function(x) as.numeric(as.character(x)))
  return(data)
}

# Convert first 3 columns from factor to numeric
columns_to_convert <- c("V1", "V2", "V3")
ozone_date <- convert_factors_to_numeric(ozone1, columns_to_convert)
ozone2 <- convert_factors_to_numeric(ozone1, columns_to_convert)

# Check data types of the columns again
data_types <- sapply(ozone_date, class)
print(data_types)

data_types2 <- sapply(ozone2, class)
print(data_types2)

```

**Create a new column "Date" that combines date columns (month, day of month, day of week) into a single column**.

```{r, warning=FALSE, echo=T, message=FALSE}

# combine Day and Month to create a Date column
ozone_date <- ozone_date %>%
  mutate(Date = as.Date(paste(1976, V1, V2, sep = "-"), format = "%Y-%m-%d"))

# Verify the new Date column
head(ozone_date, n=10)

```

**Columns were renamed for clearer interpretation during analysis**

* **Ozone_reading:** Daily maximum one-hour-average ozone reading
* **Month:** 1 = January, ..., 12 = December
* **Day of month:** 1-30/31
* **Day of week:** 1 = Monday, ..., 7 = Sunday
* **Pressure_afb:** 500 millibar pressure height (m) measured at Vandenberg AFB
* **Wind_speed_LAX:** Wind speed (mph) at Los Angeles International Airport (LAX)
* **Humidity_LAX:** Humidity (%) at LAX
* **Temp_sandburg:** Temperature (degrees F) measured at Sandburg, CA
* **Temp_EM:** Temperature (degrees F) measured at El Monte, CA
* **IBH_LAX:** Inversion base height (feet) at LAX
* **Pressure_gradient:** Pressure gradient (mm Hg) from LAX to Daggett, CA
* **IBT_LAX:** Inversion base temperature (degrees F) at LAX
* **Visibility_LAX:** Visibility (miles) measured at LAX

```{r, warning=FALSE, echo=T, message=FALSE}

# rename columns
ozone2 <- plyr::rename(ozone1, c('V4'="Ozone_reading",
                                 'V1'="Month", 
                                 'V2'="Day_of_month",
                                 'V3'="Day_of_week", 
                                 'V5'="Pressure_afb", 
                                 'V6'="Wind_speed_LAX", 
                                 'V7'="Humidity_LAX", 
                                 'V8'="Temp_sandburg", 
                                 'V9'="Temp_EM", 
                                 'V10'="IBH_LAX", 
                                 'V11'="Pressure_gradient", 
                                 'V12'="IBT_LAX", 
                                 'V13'="Visibility_LAX"))

ozone_date2 <- plyr::rename(ozone_date, c('V4'="Ozone_reading",
                                 'V1'="Month", 
                                 'V2'="Day_of_month",
                                 'V3'="Day_of_week", 
                                 'V5'="Pressure_afb", 
                                 'V6'="Wind_speed_LAX", 
                                 'V7'="Humidity_LAX", 
                                 'V8'="Temp_sandburg", 
                                 'V9'="Temp_EM", 
                                 'V10'="IBH_LAX", 
                                 'V11'="Pressure_gradient", 
                                 'V12'="IBT_LAX", 
                                 'V13'="Visibility_LAX"))

head(ozone2, n=10)
head(ozone_date2, n=10)

```

**Data Exploration: Summary Statistics by Day of Week**

No notable trend in ozone levels by day of the week, except that mean and median ozone levels appear to be lower on day 4 of the week (Thursdays).

```{r, warning=FALSE, echo=T, message=FALSE}

# Summary statistics by day of the week 
ozone_summary_by_day <- ozone2 %>%
  group_by(Day_of_week) %>%
  summarize(
    mean_ozone = mean(Ozone_reading, na.rm = TRUE),
    median_ozone = median(Ozone_reading, na.rm = TRUE),
    max_ozone = max(Ozone_reading, na.rm = TRUE),
    min_ozone = min(Ozone_reading, na.rm = TRUE)
  )

print(ozone_summary_by_day)

```

**Data Exploration: Summary Statistics by Month**

Mean and median ozone levels are lowest in the months of January, February, and March on average. They increase during the summer months, peaking in July, and gradually decline through the remainder of the year. 

```{r, warning=FALSE, echo=T, message=FALSE}

ozone_summary_by_month <- ozone2 %>%
  group_by(Month) %>%
  summarize(
    mean_ozone = mean(Ozone_reading, na.rm = TRUE),
    median_ozone = median(Ozone_reading, na.rm = TRUE),
    max_ozone = max(Ozone_reading, na.rm = TRUE),
    min_ozone = min(Ozone_reading, na.rm = TRUE)
  )

print(ozone_summary_by_month)

```


**Examine how feature variables correlate with Ozone levels**

Correlation coefficients were determined for each variable with respect to Ozone levels, the response variable. A bar graph was used to summarize the correlation coefficients. The variables with strong correlations were:

* **Strong Positive Correlations:** Humidity_LAX, Pressure_afb, IBT_LAX, Temp_EM, and Temp_sandburg
* **Strong Negative Correlations:** IBH_LAX and Visibility_LAX

```{r, warning=FALSE, echo=T, message=FALSE}

# Make sure data is in numeric form
ozone2[] <- lapply(ozone2, as.numeric)

# Calculate correlations with Ozone
corr_coeffs <- cor(ozone2, use = "complete.obs")['Ozone_reading', ]
corr_coeffs <- corr_coeffs[!names(corr_coeffs) %in% 'Ozone_reading']

# Create a data frame for plotting
corr_df <- data.frame(Variable = names(corr_coeffs), Correlation = corr_coeffs)

# Create the bar graph
ggplot(corr_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
  geom_bar(stat = 'identity',fill = "blue") +
  xlab('Variable') +
  ylab('Correlation Coefficient') +
  ggtitle('Correlation Between Variables and Daily Average Ozone Reading') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

**Explore Interactions with Positively Correlated Variables**

**Strong Positive Correlations:** Humidity_LAX, Pressure_afb, IBT_LAX, Temp_EM, and Temp_sandburg

The percentage of ozone readings appears to be approximately normally distributed with respect to Pressure_afb, IBT_LAX, and Temp_sandburg. There appears to be some negative skew with respect to humidity, with a secondary mode at the lowest humidity bin (10-20). There are a lot of missing data points for Temp_EM (139 observations out of 366), as discussed in the initial data summary. This represents 38.0% of the observations for Temp_EM.

```{r, warning=FALSE, echo=T, message=FALSE}

## Humidity
# Create bins for humidity levels
ozone3 <- ozone2 %>%
  mutate(humidity_bin = cut(Humidity_LAX, breaks = seq(10, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data1 <- ozone3 %>%
  group_by(humidity_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data1, aes(x = humidity_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Humidity Levels",
       x = "Humidity Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()


## Pressure
# Create bins for humidity levels
ozone3 <- ozone2 %>%
  mutate(pressure_bin = cut(Pressure_afb, breaks = seq(5300, 6000, by = 100), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data2 <- ozone3 %>%
  group_by(pressure_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data2, aes(x = pressure_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Pressure Levels",
       x = "Pressure Levels",
       y = "Percentage of Ozone Readings") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5, size=8))


## IBT - Inversion base temperature (degrees F) at LAX
# Create bins for Inversion base temp levels
ozone3 <- ozone2 %>%
  mutate(IBT_bin = cut(IBT_LAX, breaks = seq(20, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data3 <- ozone3 %>%
  group_by(IBT_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data3, aes(x = IBT_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Inversion base temp Levels",
       x = "Inversion base temp Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()


## Temp_EM - Temperature (degrees F) measured at El Monte, CA
# Create bins for temp levels
ozone3 <- ozone2 %>%
  mutate(Temp_EM_bin = cut(Temp_EM, breaks = seq(20, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data4 <- ozone3 %>%
  group_by(Temp_EM_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data4, aes(x = Temp_EM_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Temp at El Monte Levels",
       x = "Temp Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()


## Temp_sandburg
# Create bins for temp levels
ozone3 <- ozone2 %>%
  mutate(Temp_sd_bin = cut(Temp_sandburg, breaks = seq(20, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data5 <- ozone3 %>%
  group_by(Temp_sd_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data5, aes(x = Temp_sd_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Temp at Sandburg Levels",
       x = "Temp Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()

```

**Explore Interactions with Negatively Correlated Variables**

* **Strong Negative Correlations:** IBH_LAX and Visibility_LAX

The percentage of ozone readings does not appear to be normally distributed with respect to IBH_LAX and Visbility_LAX. The highest proportion of Ozone readings are at high IBH (4600-5100), with a secondary mode at low IBH (600-1100). The proportion of Ozone readings are positively skewed with respect to Visbility_LAX, with the mode occurring between 50 and 100, and a secondary mode occuring between 250 and 300. 


```{r, warning=FALSE, echo=T, message=FALSE}

## IBH_LAX - Inversion base height (feet) at LAX
# Create bins for IBH levels
ozone3 <- ozone2 %>%
  mutate(IBH_bin = cut(IBH_LAX, breaks = seq(100, 5500, by = 500), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data6 <- ozone3 %>%
  group_by(IBH_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data6, aes(x = IBH_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by IBH Levels",
       x = "IBH Levels",
       y = "Percentage of Ozone Readings") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5))


## Visibility
# Create bins for Visibility levels
ozone3 <- ozone2 %>%
  mutate(visibility_bin = cut(Visibility_LAX, breaks = seq(0, 500, by = 50), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data7 <- ozone3 %>%
  group_by(visibility_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data7, aes(x = visibility_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Visibility Levels",
       x = "Visibility Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()

```

**Exploration of the Missing Data**

The total number of missing data points for each column is shown below as a count and as a percentage. Most of the columns contain <5% missing values. **Temp_EM contains 139 missing values, which is 38.0% of the observations.** The total number of missing values in the dataset is 203 out of 4,768 (13 columns times 366 obervations). This represents 4.3% of the entire dataset. 

```{r, warning=FALSE, echo=T, message=FALSE}

# Function to summarize missing values in a data frame
summarize_missing_values <- function(data) {
  data %>%
    summarize_all(~ sum(is.na(.))) %>%
    gather(key = "column", value = "missing_values") %>%
    mutate(missing_percentage = (missing_values / nrow(data)) * 100)
}

missing_summary <- summarize_missing_values(ozone2)

# Print the summary of missing values
print(missing_summary)
print(sum(is.na(ozone2)))
```

**Visualization of the Missing Data**

Three different plots were generating to visualize the missing data. The first uses the vis_miss() function and the resulting plot shows the missing values shaded in black for each column and each row. Since the rows are arranged by date, we can see that the most of the data are missing in random clusters with respect to date. Temp_EM, which has the highest proportion of missing data (38%), appears to be missing in pretty regular intervals. This was further explored in the next section.

The second plot uses the gg_miss_upset() function. This plot shows the number of missing values not only by each column, but by each possbile combination of missing values (intersections). For example, the third bar in this figure shows that there are 9 rows that are missing values for IBT_LAX, Humidity_LAX, and IBH_LAX. The majority of the rows with missing data appear to be only missing Temp_EM (127). The next highest intersection is Pressure_afb_NA, which contains 10 rows.

The third plot was generated using the gg_miss_var() function and shows the number of missing values for each variable. Again, Temp_EM has by far the largest number of missing points (139).


```{r, warning=FALSE, echo=T, message=FALSE}

#Shows what percentage of the data are missing from each column
vis_miss(ozone2)


#This plot gives a visual of what combinations of NAs are present and how many there are for each
#set nsets to 8 since we have 8 columns with missing data
gg_miss_upset(ozone2, nsets=8)


#Another way to visualize number of missing rows per column
gg_miss_var(ozone2) + ylim(0, 150)

```

**Further Visualization of the Missing Data: Missingness Patterns**

The data were further visualized using the gg_miss_fct() function to plot the proportion of missing values for each column (y-axis) broken down by one variable as a time (x-axis). The purpose of this is to determine if there are discernable patterns in the missingness of the data. This provides supportive information for classiflying the data as MCAR, MAR, or MNAR.

Focusing on Temp_EM since it is the column with the highest number of missing values, the data appear to be missing randomly with respect to most of the variables. With respect to the date columns, the pattern of missingness appears to be random with respect to day of the month. However, it is apparent that there is a high proportion of missing data on days 6 and 7 of the week (Saturdays and Sundays). This indicates that Temp_EM was likely not measured on the weekends throughout the year. The values for Temp_EM also appear to be missing randomly with respect to month, though there is a notable high frequency of missing data around the month of May.

For the other variables in the dataset, there does not appear to be any obvious patterns to the missing data. Most importantly, the frequency of missing data for Temp_EM does not appear to depend on the output variable (ozone reading). Therefore, we can most likely proceed to imputation with the assumption that our data are missing at random (MAR), since there is some dependency of the missing data on other input variables such as day of week and month.

```{r, warning=FALSE, echo=T, message=FALSE}

# Create gg_miss_fct plots with adjusted themes
p1 <- gg_miss_fct(ozone2, fct = Month) + 
  ggtitle("Missing Data by Month") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p2 <- gg_miss_fct(ozone2, fct = Day_of_month) + 
  ggtitle("Missing Data by Day of Month") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p3 <- gg_miss_fct(ozone2, fct = Day_of_week) + 
  ggtitle("Missing Data by Day of Week") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p4 <- gg_miss_fct(ozone2, fct = Ozone_reading) + 
  ggtitle("Missing Data by Ozone Reading") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p5 <- gg_miss_fct(ozone2, fct = Pressure_afb) + 
  ggtitle("Missing Data by Solar Radiation") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p6 <- gg_miss_fct(ozone2, fct = Wind_speed_LAX) + 
  ggtitle("Missing Data by Wind Speed") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p7 <- gg_miss_fct(ozone2, fct = Humidity_LAX) + 
  ggtitle("Missing Data by Humidity (LAX)") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p8 <- gg_miss_fct(ozone2, fct = Temp_sandburg) + 
  ggtitle("Missing Data by Temperature (Sandburg)") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p9 <- gg_miss_fct(ozone2, fct = Temp_EM) + 
  ggtitle("Missing Data by Temperature (EM)") +
  theme(plot.title = element_text(size=8))

p10 <- gg_miss_fct(ozone2, fct = IBH_LAX) + 
  ggtitle("Missing Data by IBH_LAX") +
  theme(plot.title = element_text(size=8))

p11 <- gg_miss_fct(ozone2, fct = Pressure_gradient) + 
  ggtitle("Missing Data by Pressure Gradient") +
  theme(plot.title = element_text(size=8))

p12 <- gg_miss_fct(ozone2, fct = IBT_LAX) + 
  ggtitle("Missing Data by IBT_LAX") +
  theme(plot.title = element_text(size=8))

p13 <- gg_miss_fct(ozone2, fct = Visibility_LAX) + 
  ggtitle("Missing Data by Visibility_LAX") +
  theme(plot.title = element_text(size=8))

# Arrange the plots into grids with proper spacing
grid1 <- grid.arrange(p1, p2, p3, p4, nrow = 2)
grid2 <- grid.arrange(p5, p6, p7, p8, nrow = 2)
grid3 <- grid.arrange(p9, p10, p11, nrow = 2)
grid4 <- grid.arrange(p12, p13, nrow = 1)

```

**Missing Data Imputation Using Simple Methods**

Missing data were imputed using either the mean, median or mode as a demonstration of simple imputation techniques. With mean, median, or mode imputation, all NA values are replaced by a single value for each column: the mean, median, or mode of that column. Three data frames were created: one where mean imputation was used, a second where median imputation was used, and the last where mode imputation was used.

```{r, warning=FALSE, echo=T, message=FALSE}

# Function for mean imputation
mean_impute <- function(x) {
  x[is.na(x)] <- mean(x, na.rm = TRUE)
  return(x)
}

# Function for median imputation
median_impute <- function(x) {
  x[is.na(x)] <- median(x, na.rm = TRUE)
  return(x)
}

# Function for mode imputation (using the most common value)
mode_impute <- function(x) {
  mode_val <- as.numeric(names(sort(table(x), decreasing = TRUE)[1]))
  x[is.na(x)] <- mode_val
  return(x)
}

# Apply imputation methods
imputed_data_mean <- apply(ozone2, 2, mean_impute)
imputed_data_mean <- data.frame(imputed_data_mean)

imputed_data_median <- apply(ozone2, 2, median_impute)
imputed_data_median <- data.frame(imputed_data_median)

imputed_data_mode <- apply(ozone2, 2, mode_impute)
imputed_data_mode <- data.frame(imputed_data_mode)

# Print results
head(imputed_data_mean)
head(imputed_data_median)
head(imputed_data_mode)


#Confirm there are no more NA's in each respective dataset
print(sum(is.na(imputed_data_mean)))
print(sum(is.na(imputed_data_median)))
print(sum(is.na(imputed_data_mode)))

```

**Missing Data Imputation Using MICE (Multiple Imputation Method) and Random Forest (Machine Learning Method)**

Next, the missing data were imputed using MICE and Miss_Forest methods. 


```{r, warning=FALSE, echo=T, message=FALSE, results=FALSE}

library(missForest)

# verbose = If 'TRUE' the user is supplied with additional output between iterations
# xtrue = Complete data matrix
ozone2_mf <- missForest(ozone2, xtrue = ozone2, verbose = TRUE)
# convert back to data frame
ozone2_mf <- as.data.frame(ozone2_mf$ximp)
print(sum(is.na(ozone2_mf)))

## The final results can be accessed directly. The estimated error:
ozone2_mf$OOBerror

## The true imputation error (if available):
ozone2_mf$error


library(mice)

# Impute missing values using MICE
# pmm = Predictive Mean Matching (suitable for continuous variables like temperature, wind, etc.)
# m = 5: number of imputed datasets to create.
# maxit = 50: max number of iterations
ozone2_mice <- mice(ozone2, method = "pmm", m = 5, maxit = 50)
# extracts the completed datasets from the mice object
ozone2_mice <- complete(ozone2_mice)
# Convert completed data to data frame
ozone2_mice <- as.data.frame(ozone2_mice)

print(sum(is.na(ozone2_mice)))

```

***Make Predictions Using Data Where Missing Values Were Imputed Using the Mean**

The mean imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors
* Decision Tree
* SVM

After models were fit to the training data, predictions were made on the unseen test data. RMSE and R-Squared were then reported for each model. The SVM model resulted in the lowest RMSE (4.89) for predicted ozone levels when using mean imputation.

```{r, warning=FALSE, echo=T, message=FALSE}

#Load additional libraries for model fitting
library(caret) # for fitting KNN models
library(e1071) # svm model
library(rsample) # for creating validation splits
library(recipes)    # for feature engineering
library(randomForest)
library(rpart)# decision tree
library(tidymodels) 

# Split the data into training and testing sets
set.seed(123)
data_split_mean <- initial_split(imputed_data_mean, prop = 0.75)
train_mean <- training(data_split_mean)
test_mean <- testing(data_split_mean)

# Split data into predictors and target
X <- train_mean[, -1]  # Features
y <- train_mean$Ozone_reading  # Target


# Random forest model
rf_mean <- randomForest(Ozone_reading ~ ., data = train_mean)
# make predictions
rf_mean_pred <- predict(rf_mean, newdata = test_mean)
# Plot variable importance
varImpPlot(rf_mean, main = "Variable Importance Plot for Random Forest Model")


# KNN model
knn_mean <- train(Ozone_reading ~ ., data = train_mean, method = "knn")
# make predictions
knn_mean_pred <- predict(knn_mean, newdata = test_mean)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")


# Decision tree model
tree_mean <- rpart(Ozone_reading ~ ., data = train_mean)
# make predictions
tree_mean_pred <- predict(tree_mean, newdata = test_mean)
# Plot variable importance
var_importance <- varImp(tree_mean)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

# SVM model
svm_mean <- svm(Ozone_reading ~ ., data = train_mean)
# make predictions
svm_mean_pred <- predict(svm_mean, newdata = test_mean)
# Plot variable importance



# Function to calculate RMSE
rmse <- function(pred, actual) {
  sqrt(mean((pred - actual)^2))
}

# Define a function to calculate R-squared
r_squared <- function(actual, pred) {
  mean_actual <- mean(actual)
  ss_tot <- sum((actual - mean_actual)^2)
  ss_res <- sum((actual - pred)^2)
  
  # Check if ss_tot is 0, which would lead to division by zero
  if (ss_tot == 0) {
    r2 <- NaN  # Handle case where ss_tot is 0
  } else {
    r2 <- 1 - (ss_res / ss_tot)
  }
  
  return(r2)
}

# Calculate RMSE for each model
rf_mean_rmse <- rmse(rf_mean_pred, test_mean$Ozone_reading)
knn_mean_rmse <- rmse(knn_mean_pred, test_mean$Ozone_reading)
tree_mean_rmse <- rmse(tree_mean_pred, test_mean$Ozone_reading)
svm_mean_rmse <- rmse(svm_mean_pred, test_mean$Ozone_reading)

rf_mean_r2 <- r_squared(test_mean$Ozone_reading, rf_mean_pred)
knn_mean_r2 <- r_squared(test_mean$Ozone_reading, knn_mean_pred)
tree_mean_r2 <- r_squared(test_mean$Ozone_reading, tree_mean_pred)
svm_mean_r2 <- r_squared(test_mean$Ozone_reading, svm_mean_pred)

# Print RMSE values
cat("Random Forest RMSE:", rf_mean_rmse, "\n")
cat("KNN RMSE:", knn_mean_rmse, "\n")
cat("Decision Tree RMSE:", tree_mean_rmse, "\n")
cat("SVM RMSE:", svm_mean_rmse, "\n")

cat("Random Forest R-squared:", rf_mean_r2["Rsquared"], "\n")
cat("KNN R-squared:", knn_mean_r2["Rsquared"], "\n")
cat("Decision Tree R-squared:", tree_mean_r2["Rsquared"], "\n")
cat("SVM R-squared:", svm_mean_r2["Rsquared"], "\n")

```

***Make Predictions Using Data Where Missing Values Were Imputed Using the Median**

The median imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors
* Decision Tree
* SVM

After models were fit to the training data, predictions were made on the unseen test data. RMSE and R-Squared were then reported for each model. The SVM model resulted in the lowest RMSE (4.98) for predicted ozone levels when using median imputation.

```{r, warning=FALSE, echo=T, message=FALSE}

# Split the data into training and testing sets
set.seed(123)
data_split_med <- initial_split(imputed_data_median, prop = 0.75)
train_med <- training(data_split_med)
test_med <- testing(data_split_med)


# Random forest model
rf_med <- randomForest(Ozone_reading ~ ., data = train_med)
rf_med_pred <- predict(rf_med, newdata = test_med)
# Plot variable importance
varImpPlot(rf_med, main = "Variable Importance Plot for Random Forest Model")

# KNN model
knn_med <- train(Ozone_reading ~ ., data = train_med, method = "knn")
knn_med_pred <- predict(knn_med, newdata = test_med)
# Plot variable importance


# Decision tree model
tree_med <- ctree(Ozone_reading ~ ., data = train_med)
tree_med_pred <- predict(tree_med, newdata = test_med)
# Plot variable importance


# SVM model
svm_med <- svm(Ozone_reading ~ ., data = train_med)
svm_med_pred <- predict(svm_med, newdata = test_med)
# Plot variable importance



# Calculate RMSE for each model
rf_med_rmse <- rmse(rf_med_pred, test_med$Ozone_reading)
knn_med_rmse <- rmse(knn_med_pred, test_med$Ozone_reading)
tree_med_rmse <- rmse(tree_med_pred, test_med$Ozone_reading)
svm_med_rmse <- rmse(svm_med_pred, test_med$Ozone_reading)

rf_med_r2 <- r_squared(test_med$Ozone_reading, rf_med_pred)
knn_med_r2 <- r_squared(test_med$Ozone_reading, knn_med_pred)
tree_med_r2 <- r_squared(test_med$Ozone_reading, tree_med_pred)
svm_med_r2 <- r_squared(test_med$Ozone_reading, svm_med_pred)

# Print RMSE values
cat("Random Forest RMSE:", rf_med_rmse, "\n")
cat("KNN RMSE:", knn_med_rmse, "\n")
cat("Decision Tree RMSE:", tree_med_rmse, "\n")
cat("SVM RMSE:", svm_med_rmse, "\n")

cat("Random Forest R-squared:", rf_med_r2["Rsquared"], "\n")
cat("KNN R-squared:", knn_med_r2["Rsquared"], "\n")
cat("Decision Tree R-squared:", tree_med_r2["Rsquared"], "\n")
cat("SVM R-squared:", svm_med_r2["Rsquared"], "\n")


```

***Make Predictions Using Data Where Missing Values Were Imputed Using the Mode**

The mode imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors
* Decision Tree
* SVM

After models were fit to the training data, predictions were made on the unseen test data. RMSE and R-Squared were then reported for each model. The SVM model resulted in the lowest RMSE (5.39) for predicted ozone levels when using mode imputation.

```{r, warning=FALSE, echo=T, message=FALSE}

# Split the data into training and testing sets
set.seed(123)
data_split_mode <- initial_split(imputed_data_mode, prop = 0.75)
train_mode <- training(data_split_mode)
test_mode <- testing(data_split_mode)


# Random forest model
rf_mode <- randomForest(Ozone_reading ~ ., data = train_mode)
rf_mode_pred <- predict(rf_mode, newdata = test_mode)
# Plot variable importance
varImpPlot(rf_mode, main = "Variable Importance Plot for Random Forest Model")

# KNN model
knn_mode <- train(Ozone_reading ~ ., data = train_mode, method = "knn")
knn_mode_pred <- predict(knn_mode, newdata = test_mode)
# Plot variable importance


# Decision tree model
tree_mode <- ctree(Ozone_reading ~ ., data = train_mode)
tree_mode_pred <- predict(tree_mode, newdata = test_mode)
# Plot variable importance


# SVM model
svm_mode <- svm(Ozone_reading ~ ., data = train_mode)
svm_mode_pred <- predict(svm_mode, newdata = test_mode)
# Plot variable importance



# Calculate RMSE for each model
rf_mode_rmse <- rmse(rf_mode_pred, test_mode$Ozone_reading)
knn_mode_rmse <- rmse(knn_mode_pred, test_mode$Ozone_reading)
tree_mode_rmse <- rmse(tree_mode_pred, test_mode$Ozone_reading)
svm_mode_rmse <- rmse(svm_mode_pred, test_mode$Ozone_reading)

rf_mode_r2 <- r_squared(test_mean$Ozone_reading, rf_mode_pred)
knn_mode_r2 <- r_squared(test_mean$Ozone_reading, knn_mode_pred)
tree_mode_r2 <- r_squared(test_mean$Ozone_reading, tree_mode_pred)
svm_mode_r2 <- r_squared(test_mean$Ozone_reading, svm_mode_pred)

# Print RMSE values
cat("Random Forest RMSE:", rf_mode_rmse, "\n")
cat("KNN RMSE:", knn_mode_rmse, "\n")
cat("Decision Tree RMSE:", tree_mode_rmse, "\n")
cat("SVM RMSE:", svm_mode_rmse, "\n")

cat("Random Forest R-squared:", rf_mode_r2["Rsquared"], "\n")
cat("KNN R-squared:", knn_mode_r2["Rsquared"], "\n")
cat("Decision Tree R-squared:", tree_mode_r2["Rsquared"], "\n")
cat("SVM R-squared:", svm_mode_r2["Rsquared"], "\n")

```

***Make Predictions Using Data Where Missing Values Were Imputed Using MissForest**

The missForest imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors
* Decision Tree
* SVM

After models were fit to the training data, predictions were made on the unseen test data. RMSE and R-Squared were then reported for each model. The SVM model resulted in the lowest RMSE (4.17) for predicted ozone levels when using missForest for imputation.

```{r, warning=FALSE, echo=T, message=FALSE}

# Split the data into training and testing sets
set.seed(123)
data_split_miss <- initial_split(ozone2_mf, prop = 0.75)
train_miss <- training(data_split_miss)
test_miss <- testing(data_split_miss)


# Random forest model
rf_miss <- randomForest(Ozone_reading ~ ., data = train_miss)
rf_miss_pred <- predict(rf_miss, newdata = test_miss)
# Plot variable importance
varImpPlot(rf_miss, main = "Variable Importance Plot for Random Forest Model")

# KNN model
knn_miss <- train(Ozone_reading ~ ., data = train_miss, method = "knn")
knn_miss_pred <- predict(knn_miss, newdata = test_miss)
# Plot variable importance


# Decision tree model
tree_miss <- ctree(Ozone_reading ~ ., data = train_miss)
tree_miss_pred <- predict(tree_miss, newdata = test_miss)
# Plot variable importance


# SVM model
svm_miss <- svm(Ozone_reading ~ ., data = train_miss)
svm_miss_pred <- predict(svm_miss, newdata = test_miss)
# Plot variable importance



# Calculate RMSE for each model
rf_miss_rmse <- rmse(rf_miss_pred, test_miss$Ozone_reading)
knn_miss_rmse <- rmse(knn_miss_pred, test_miss$Ozone_reading)
tree_miss_rmse <- rmse(tree_miss_pred, test_miss$Ozone_reading)
svm_miss_rmse <- rmse(svm_miss_pred, test_miss$Ozone_reading)

rf_miss_r2 <- r_squared(test_mean$Ozone_reading, rf_miss_pred)
knn_miss_r2 <- r_squared(test_mean$Ozone_reading, knn_miss_pred)
tree_miss_r2 <- r_squared(test_mean$Ozone_reading, tree_miss_pred)
svm_miss_r2 <- r_squared(test_mean$Ozone_reading, svm_miss_pred)

# Print RMSE values
cat("Random Forest RMSE:", rf_miss_rmse, "\n")
cat("KNN RMSE:", knn_miss_rmse, "\n")
cat("Decision Tree RMSE:", tree_miss_rmse, "\n")
cat("SVM RMSE:", svm_miss_rmse, "\n")

cat("Random Forest R-squared:", rf_miss_r2["Rsquared"], "\n")
cat("KNN R-squared:", knn_miss_r2["Rsquared"], "\n")
cat("Decision Tree R-squared:", tree_miss_r2["Rsquared"], "\n")
cat("SVM R-squared:", svm_miss_r2["Rsquared"], "\n")


```

***Make Predictions Using Data Where Missing Values Were Imputed Using MICE**

The MICE imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors
* Decision Tree
* SVM

After models were fit to the training data, predictions were made on the unseen test data. RMSE and R-Squared were then reported for each model. The SVM model resulted in the lowest RMSE (4.13) for predicted ozone levels when using MICE for imputation.


```{r, warning=FALSE, echo=T, message=FALSE}

# Split the data into training and testing sets
set.seed(123)
data_split_mice <- initial_split(ozone2_mice, prop = 0.75)
train_mice <- training(data_split_mice)
test_mice <- testing(data_split_mice)


# Random forest model
rf_mice <- randomForest(Ozone_reading ~ ., data = train_mice)
rf_mice_pred <- predict(rf_mice, newdata = test_mice)
# Plot variable importance
varImpPlot(rf_mice, main = "Variable Importance Plot for Random Forest Model")

# KNN model
knn_mice <- train(Ozone_reading ~ ., data = train_mice, method = "knn")
knn_mice_pred <- predict(knn_mice, newdata = test_mice)
# Plot variable importance


# Decision tree model
tree_mice <- ctree(Ozone_reading ~ ., data = train_mice)
tree_mice_pred <- predict(tree_mice, newdata = test_mice)
# Plot variable importance


# SVM model
svm_mice <- svm(Ozone_reading ~ ., data = train_mice)
svm_mice_pred <- predict(svm_mice, newdata = test_mice)
# Plot variable importance



# Calculate RMSE for each model
rf_mice_rmse <- rmse(rf_mice_pred, test_mice$Ozone_reading)
knn_mice_rmse <- rmse(knn_mice_pred, test_mice$Ozone_reading)
tree_mice_rmse <- rmse(tree_mice_pred, test_mice$Ozone_reading)
svm_mice_rmse <- rmse(svm_mice_pred, test_mice$Ozone_reading)

rf_mice_r2 <- r_squared(test_mean$Ozone_reading, rf_mice_pred)
knn_mice_r2 <- r_squared(test_mean$Ozone_reading, knn_mice_pred)
tree_mice_r2 <- r_squared(test_mean$Ozone_reading, tree_mice_pred)
svm_mice_r2 <- r_squared(test_mean$Ozone_reading, svm_mice_pred)

# Print RMSE values
cat("Random Forest RMSE:", rf_mice_rmse, "\n")
cat("KNN RMSE:", knn_mice_rmse, "\n")
cat("Decision Tree RMSE:", tree_mice_rmse, "\n")
cat("SVM RMSE:", svm_mice_rmse, "\n")

cat("Random Forest R-squared:", rf_mice_r2["Rsquared"], "\n")
cat("KNN R-squared:", knn_mice_r2["Rsquared"], "\n")
cat("Decision Tree R-squared:", tree_mice_r2["Rsquared"], "\n")
cat("SVM R-squared:", svm_mice_r2["Rsquared"], "\n")


```

**Summarize Model Performance for Each Imputation Methodology**

The RMSE for each model and imputation method combination was summarized into a data frame. The results are shown below. The best model fit (lowest RMSE) was obtained when using MICE for imputation of missing data and the SVM algorithm for model training with the imputed dataset. Mean imputation with SVM model fitting was the second best combination, followed by median imputation with Random Forest.

```{r, warning=FALSE, echo=T, message=FALSE}

# Create data frame with RSME scores
models <- c('RandomForest', 'KNN', 'DecisionTree', 'SVM')
scores <- c(rf_mean_rmse,knn_mean_rmse,tree_mean_rmse,svm_mean_rmse, 
            rf_med_rmse,knn_med_rmse,tree_med_rmse,svm_med_rmse,
            rf_mode_rmse,knn_mode_rmse,tree_mode_rmse,svm_mode_rmse,
            rf_miss_rmse,knn_miss_rmse,tree_miss_rmse,svm_miss_rmse,
            rf_mice_rmse,knn_mice_rmse,tree_mice_rmse,svm_mice_rmse)
ImpMethod <- c('Mean', 'Median', 'Mode','missForest','MICE')

# Create dataframe
rmse_df <- data.frame(Model = models, ImpMethod=ImpMethod,RMSE = scores)
rmse_df[order(rmse_df$RMSE),]

```


### Conclusion

## References
