---
title: "Exploration of Different Imputation Methods for Missing Data"
author: "Karthik Aerra, Liz Miller, Mohit Kumar Veeraboina, Robert Stairs"
date: '`r Sys.Date()`'
format:
  revealjs:
    theme: simple
    smaller: true
    scrollable: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

# Introduction

## Placeholder Title 1

- Bullet 1
- Bullet 2
- Bullet 3

## Placeholder Title 2

- Bullet 1
- Bullet 2
- Bullet 3

## Placeholder Title 3

- Bullet 1
- Bullet 2
- Bullet 3

## Placeholder Title 4

- Bullet 1
- Bullet 2
- Bullet 3

## Placeholder Title 5

- Bullet 1
- Bullet 2
- Bullet 3

# Methods

## Placeholder Title 6

- Bullet 1
- Bullet 2
- Bullet 3

## Placeholder Title 7

- Bullet 1
- Bullet 2
- Bullet 3

## Placeholder Title 8

- Bullet 1
- Bullet 2
- Bullet 3


## Placeholder Title 9

- Bullet 1
- Bullet 2
- Bullet 3

# Analysis and Results

## Introduction to the Dataset

- “Ozone: Los Angeles Ozone Pollution Data, 1976” from mlbench package in R ("Ozone")
- It contains observations related to pollution levels in the Los Angeles area during 1976.
- It contains a total of 13 variables, 366 observations (one for each day for one year)
- We chose this dataset due to the **high volume of already-missing data**
- Demonstration of a real-life scenario, where missing values are truly unknown and effectiveness of imputation methods cannot directly be measured.
- It is up to the investigator to choose a methodology for handling the missing data and appropriate metrics for evaluating effectiveness of missing data methods


## Variables in the Ozone Dataset

- V1: Month, 1-12, where 1 is January and 12 is December
- V2: Day of month
- V3: Day of week, 1-7, where 1 is Monday and 7 is Sunday
- V4:	Daily maximum one-hour-average ozone reading
- V5: 500 millibar pressure height (m) measured at Vandenberg AFB
- V6:	Wind speed (mph) at  Los Angeles International Airport (LAX)
- V7:	Humidity (%) at LAX
- V8:	Temperature (degrees F) measured at Sandburg, CA
- V9:	Temperature (degrees F) measured at El Monte, CA
- V10: Inversion base height (feet) at LAX
- V11: Pressure gradient (mm Hg) from LAX to Daggett, CA
- V12: Inversion base temperature (degrees F) at LAX
- V13: Visibility (miles) measured at LAX


```{r, warning=FALSE, echo=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(mlbench)
library(dplyr)
library(ggplot2)
library(vtable)
library(knitr)
library(kableExtra)
library(tidyverse)
library(tidyr)
library(naniar)
library(ggplot2)
library(UpSetR)
library(corrplot)
library(gridExtra)
library(reshape2)
library(ggpubr)
library(caTools)
library(party)
library(magrittr)
library(ggfittext)
```


## Summarizing the Data

- The summary() function shows the number of NAs for each column
- Most columns have <20 NAs, however V9 contains 139 missing values
- V9: Temperature (degrees F) measured at El Monte, CA

```{r, warning=FALSE, echo=FALSE}
# import data
data("Ozone", package = "mlbench")

# convert to data frame
ozone1 <- data.frame(Ozone)
# Reorder columns
ozone1 <- ozone1 %>%
  dplyr::select(V4,V1,V2,V3,V5,V6,V7,V8,V9,V10,V11,V12,V13)

# View summary of data
summary(ozone1)
```

## Data Pre-Processing Summary

- All columns converted to numeric data type
- Renamed columns for clearer interpretation during analysis and reporting
- Combined month, day of month and day of week into one data column

```{r, warning=FALSE, echo=FALSE, message=FALSE}
# Create function to check data types of data frame columns
check_data_types <- function(ozone1) {
  sapply(ozone1, class)
}

# Check data types of the columns
data_types <- check_data_types(ozone1)


# Function to convert specified columns from factor to numeric
convert_factors_to_numeric <- function(data, columns) {
  data[columns] <- lapply(data[columns], function(x) as.numeric(as.character(x)))
  return(data)
}

# Convert first 3 columns from factor to numeric
columns_to_convert <- c("V1", "V2", "V3")
ozone_date <- convert_factors_to_numeric(ozone1, columns_to_convert)
ozone2 <- convert_factors_to_numeric(ozone1, columns_to_convert)

# Check data types of the columns again
data_types <- sapply(ozone_date, class)

data_types2 <- sapply(ozone2, class)

```

```{r, warning=FALSE, echo=FALSE, message=FALSE}

# combine Day and Month to create a Date column
ozone_date <- ozone_date %>%
  mutate(Date = as.Date(paste(1976, V1, V2, sep = "-"), format = "%Y-%m-%d"))

```

```{r, warning=FALSE, echo=FALSE, message=FALSE}

# rename columns
ozone2 <- plyr::rename(ozone1, c('V4'="Ozone_reading",
                                 'V1'="Month", 
                                 'V2'="Day_of_month",
                                 'V3'="Day_of_week", 
                                 'V5'="Pressure_afb", 
                                 'V6'="Wind_speed_LAX", 
                                 'V7'="Humidity_LAX", 
                                 'V8'="Temp_sandburg", 
                                 'V9'="Temp_EM", 
                                 'V10'="IBH_LAX", 
                                 'V11'="Pressure_gradient", 
                                 'V12'="IBT_LAX", 
                                 'V13'="Visibility_LAX"))

ozone_date2 <- plyr::rename(ozone_date, c('V4'="Ozone_reading",
                                 'V1'="Month", 
                                 'V2'="Day_of_month",
                                 'V3'="Day_of_week", 
                                 'V5'="Pressure_afb", 
                                 'V6'="Wind_speed_LAX", 
                                 'V7'="Humidity_LAX", 
                                 'V8'="Temp_sandburg", 
                                 'V9'="Temp_EM", 
                                 'V10'="IBH_LAX", 
                                 'V11'="Pressure_gradient", 
                                 'V12'="IBT_LAX", 
                                 'V13'="Visibility_LAX"))
```


## Data Exploration Summary

- Summary statistics by day of week, month
- Histograms to visualize distributions of data 
- Correlation coefficients for all features with respect to Ozone levels (output)
- **Strong Positive Correlations:** Humidity_LAX, Pressure_afb, IBT_LAX, Temp_EM, and Temp_sandburg
- **Strong Negative Correlations:** IBH_LAX and Visibility_LAX


```{r, warning=FALSE, echo=FALSE, message=FALSE, include=FALSE}

# Summary statistics by day of the week 
ozone_summary_by_day <- ozone2 %>%
  group_by(Day_of_week) %>%
  summarize(
    mean_ozone = mean(Ozone_reading, na.rm = TRUE),
    median_ozone = median(Ozone_reading, na.rm = TRUE),
    max_ozone = max(Ozone_reading, na.rm = TRUE),
    min_ozone = min(Ozone_reading, na.rm = TRUE)
  )

```

```{r, warning=FALSE, echo=FALSE, message=FALSE, include=FALSE}

ozone_summary_by_month <- ozone2 %>%
  group_by(Month) %>%
  summarize(
    mean_ozone = mean(Ozone_reading, na.rm = TRUE),
    median_ozone = median(Ozone_reading, na.rm = TRUE),
    max_ozone = max(Ozone_reading, na.rm = TRUE),
    min_ozone = min(Ozone_reading, na.rm = TRUE)
  )

```


```{r, warning=FALSE, echo=FALSE, message=FALSE}

# Make sure data is in numeric form
ozone2[] <- lapply(ozone2, as.numeric)

# Calculate correlations with Ozone
corr_coeffs <- cor(ozone2, use = "complete.obs")['Ozone_reading', ]
corr_coeffs <- corr_coeffs[!names(corr_coeffs) %in% 'Ozone_reading']

# Create a data frame for plotting
corr_df <- data.frame(Variable = names(corr_coeffs), Correlation = corr_coeffs)

# Create the bar graph
ggplot(corr_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
  geom_bar(stat = 'identity',fill = "blue") +
  xlab('Variable') +
  ylab('Correlation Coefficient') +
  ggtitle('Correlation Between Variables and Daily Average Ozone Reading') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r, warning=FALSE, echo=FALSE, message=FALSE, include=FALSE}

## Humidity
# Create bins for humidity levels
ozone3 <- ozone2 %>%
  mutate(humidity_bin = cut(Humidity_LAX, breaks = seq(10, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data1 <- ozone3 %>%
  group_by(humidity_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data1, aes(x = humidity_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Humidity Levels",
       x = "Humidity Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()


## Pressure
# Create bins for humidity levels
ozone3 <- ozone2 %>%
  mutate(pressure_bin = cut(Pressure_afb, breaks = seq(5300, 6000, by = 100), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data2 <- ozone3 %>%
  group_by(pressure_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data2, aes(x = pressure_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Pressure Levels",
       x = "Pressure Levels",
       y = "Percentage of Ozone Readings") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5, size=8))


## IBT - Inversion base temperature (degrees F) at LAX
# Create bins for Inversion base temp levels
ozone3 <- ozone2 %>%
  mutate(IBT_bin = cut(IBT_LAX, breaks = seq(20, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data3 <- ozone3 %>%
  group_by(IBT_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data3, aes(x = IBT_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Inversion base temp Levels",
       x = "Inversion base temp Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()


## Temp_EM - Temperature (degrees F) measured at El Monte, CA
# Create bins for temp levels
ozone3 <- ozone2 %>%
  mutate(Temp_EM_bin = cut(Temp_EM, breaks = seq(20, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data4 <- ozone3 %>%
  group_by(Temp_EM_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data4, aes(x = Temp_EM_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Temp at El Monte Levels",
       x = "Temp Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()


## Temp_sandburg
# Create bins for temp levels
ozone3 <- ozone2 %>%
  mutate(Temp_sd_bin = cut(Temp_sandburg, breaks = seq(20, 100, by = 10), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data5 <- ozone3 %>%
  group_by(Temp_sd_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data5, aes(x = Temp_sd_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Temp at Sandburg Levels",
       x = "Temp Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()

```

```{r, warning=FALSE, echo=FALSE, message=FALSE, include=FALSE}

## IBH_LAX - Inversion base height (feet) at LAX
# Create bins for IBH levels
ozone3 <- ozone2 %>%
  mutate(IBH_bin = cut(IBH_LAX, breaks = seq(100, 5500, by = 500), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data6 <- ozone3 %>%
  group_by(IBH_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data6, aes(x = IBH_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by IBH Levels",
       x = "IBH Levels",
       y = "Percentage of Ozone Readings") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5))


## Visibility
# Create bins for Visibility levels
ozone3 <- ozone2 %>%
  mutate(visibility_bin = cut(Visibility_LAX, breaks = seq(0, 500, by = 50), include.lowest = TRUE))

# Calculate percentage of ozone readings for each bin
percentage_data7 <- ozone3 %>%
  group_by(visibility_bin) %>%
  summarize(Ozone_reading = n()) %>%
  mutate(percentage = (Ozone_reading / sum(Ozone_reading)) * 100)

# Create the bar graph
ggplot(percentage_data7, aes(x = visibility_bin, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Percentage of Ozone Readings by Visibility Levels",
       x = "Visibility Levels",
       y = "Percentage of Ozone Readings") +
  theme_minimal()

```


## Exploration of the Missing Data

- The total number of missing data points for each column is shown below as a count and as a percentage. 
- Most of the columns contain <5% missing values. Temp_EM contains 139 missing values, which is 38.0% of the observations. 
- The total number of missing values in the dataset is 203 out of 4,768 (13 columns times 366 observations). This represents 4.3% of the entire dataset. 
- There are a few instances where more than one column has missing data, but the majority of rows with missing values are only missing Temp_EM

```{r, warning=FALSE, echo=T, message=FALSE, include=FALSE}

# Function to summarize missing values in a data frame
summarize_missing_values <- function(data) {
  data %>%
    summarize_all(~ sum(is.na(.))) %>%
    gather(key = "column", value = "missing_values") %>%
    mutate(missing_percentage = (missing_values / nrow(data)) * 100)
}

missing_summary <- summarize_missing_values(ozone2)

# Print the summary of missing values
print(missing_summary)
print(sum(is.na(ozone2)))
```


```{r, warning=FALSE, echo=FALSE, message=FALSE}
# Plot missing data pattern
#Shows what percentage of the data are missing from each column
vis_miss(ozone2)
```

```{r, warning=FALSE, echo=FALSE, message=FALSE}
#Another way to visualize number of missing rows per column
gg_miss_var(ozone2) + labs(y = "Number of missing values") + ylim(0, 150)
```


```{r, warning=FALSE, echo=FALSE, message=FALSE}
#This plot gives a visual of what combinations of NAs are present and how many there are for each
#set nsets to 8 since we have 8 columns with missing data
gg_miss_upset(ozone2, nsets=8)
```


# Statistical Testing for MCAR (Missing Completely at Random)

**Randomness Testing of Missing Data**
The Little's MCAR test was performed to analyze randomness. 
* Null Hypothesis (H0): The data is missing completely at random (MCAR).
* Alternative Hypothesis (H1): The data is not missing completely at random.
Based on the p-value(4.102052e-12) from the test, the null hypothesis is rejected, data is not missing completely at random (MCAR).
```{r, warning=FALSE, echo=T, message=FALSE}
# Perform Little's MCAR test
mcar_result <- mcar_test(ozone2)
print(mcar_result)
```

##Additionally, the Hawkin's and the Non-Parametric tests were performed to analyze missing data randomness.

**Test Data for Normality**
In order to interpret the tests, the data must be checked for normality. The Shapiro-Wilk and the Anderson-Darling tests were performed.
```{r}
# Extract the dependent variable
ozone_levels <- ozone2$Ozone_reading

# Remove NA values
ozone_levels <- na.omit(ozone_levels)

# Perform normality tests
library(nortest)
shapiro_test <- shapiro.test(ozone_levels)
ad_test <- ad.test(ozone_levels)

# Print the results
print(shapiro_test)
print(ad_test)
```
**A histogram and QQ plot were also created**
```{r}
# Histogram
ggplot(ozone2, aes(x = Ozone_reading)) + geom_histogram(binwidth = 5) + ggtitle("Histogram of Ozone")

# Q-Q plot
qqnorm(ozone2$Ozone_reading)
qqline(ozone2$Ozone_reading)
```

**Run Hawkins and Non-Parametric Tests**
```{r}
library(dplyr)
explanatory = c("Temp_EM","Month", "Day_of_month","Day_of_week", "Pressure_afb", "Wind_speed_LAX", "Humidity_LAX", "Temp_sandburg", "IBH_LAX", 
                "Pressure_gradient", "IBT_LAX", "Visibility_LAX")
dependent = "Ozone_reading"

# Run randomness test
ozone2 %>%
  select(explanatory)%>%
  MissMech::TestMCARNormality()

```

**Hawkins Test**

* P-value for the Hawkins test of normality and homoscedasticity: 0.0113103
* This test checks for both multivariate normality and homoscedasticity (equal variances).
* Interpretation: Since the p-value is less than 0.05, the null hypothesis of multivariate normality or homoscedasticity (or both) is rejected. This means that the data does not follow a multivariate normal distribution, or the variances are not equal across groups.
* MCAR Hypothesis: Provided that the above tests show that the data is not normally distributed, the hypothesis of MCAR (Missing Completely At Random) is not rejected at the 0.05 significance level.

**Non-Parametric Test**

* P-value for the non-parametric test of homoscedasticity: 0.2743229
* This test checks for homoscedasticity without assuming normality.
* Interpretation: Since the p-value is greater than 0.05, there is not enough evidence to reject the null hypothesis of homoscedasticity. This suggests that the variances are equal across groups.
* MCAR Hypothesis: There is not sufficient evidence to reject the hypothesis of MCAR at the 0.05 significance level.


**Further Visualization of the Missing Data: Missingness Patterns**

The data were further visualized using the gg_miss_fct() function to plot the proportion of missing values for each column (y-axis) broken down by one variable as a time (x-axis). The purpose of this is to determine if there are discernible patterns in the missingness of the data. This provides additional supportive information for classifying the data as MCAR, MAR, or MNAR.

Focusing on Temp_EM since it is the column with the highest number of missing values, the data appear to be missing randomly with respect to most of the variables. With respect to the date columns, the pattern of missingness appears to be random with respect to day of the month. However, it is apparent that there is a high proportion of missing data on days 6 and 7 of the week (Saturdays and Sundays). This indicates that Temp_EM was likely not measured on the weekends throughout the year. The values for Temp_EM also appear to be missing randomly with respect to month, though there is a notable high frequency of missing data around the month of May.

For the other variables in the dataset, there does not appear to be any obvious patterns to the missing data. Most importantly, the frequency of missing data for Temp_EM does not appear to depend on the output variable (ozone reading). Therefore, we can most likely proceed to imputation with the assumption that our data are missing completely at random (MCAR).

```{r, warning=FALSE, echo=T, message=FALSE}

# Create gg_miss_fct plots with adjusted themes
p1 <- gg_miss_fct(ozone2, fct = Month) + 
  ggtitle("Missing Data by Month") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p2 <- gg_miss_fct(ozone2, fct = Day_of_month) + 
  ggtitle("Missing Data by Day of Month") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p3 <- gg_miss_fct(ozone2, fct = Day_of_week) + 
  ggtitle("Missing Data by Day of Week") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p4 <- gg_miss_fct(ozone2, fct = Ozone_reading) + 
  ggtitle("Missing Data by Ozone Reading") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p5 <- gg_miss_fct(ozone2, fct = Pressure_afb) + 
  ggtitle("Missing Data by Solar Radiation") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p6 <- gg_miss_fct(ozone2, fct = Wind_speed_LAX) + 
  ggtitle("Missing Data by Wind Speed") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p7 <- gg_miss_fct(ozone2, fct = Humidity_LAX) + 
  ggtitle("Missing Data by Humidity (LAX)") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p8 <- gg_miss_fct(ozone2, fct = Temp_sandburg) + 
  ggtitle("Missing Data by Temperature (Sandburg)") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(plot.title = element_text(size=8))

p9 <- gg_miss_fct(ozone2, fct = Temp_EM) + 
  ggtitle("Missing Data by Temperature (EM)") +
  theme(plot.title = element_text(size=8))

p10 <- gg_miss_fct(ozone2, fct = IBH_LAX) + 
  ggtitle("Missing Data by IBH_LAX") +
  theme(plot.title = element_text(size=8))

p11 <- gg_miss_fct(ozone2, fct = Pressure_gradient) + 
  ggtitle("Missing Data by Pressure Gradient") +
  theme(plot.title = element_text(size=8))

p12 <- gg_miss_fct(ozone2, fct = IBT_LAX) + 
  ggtitle("Missing Data by IBT_LAX") +
  theme(plot.title = element_text(size=8))

p13 <- gg_miss_fct(ozone2, fct = Visibility_LAX) + 
  ggtitle("Missing Data by Visibility_LAX") +
  theme(plot.title = element_text(size=8))

# Arrange the plots into grids with proper spacing
grid1 <- grid.arrange(p1, p2, p3, p4, nrow = 2)
grid2 <- grid.arrange(p5, p6, p7, p8, nrow = 2)
grid3 <- grid.arrange(p9, p10, p11, nrow = 2)
grid4 <- grid.arrange(p12, p13, nrow = 1)

```

#### **Missing Data Imputation Using Simple Methods**

Missing data were deleted using listwise deletion or feature selection as a baseline comparison for imputation methods. Additionally, missing data imputed using mean, median or mode as a demonstration of simple imputation techniques. Listwise deletion is simply deleting all rows that contain a missing value. Feature removal is where a column is deleted if its total percentage of missing values is over a set threshold (we chose 20%). With  mean, median, or mode imputation, all NA values are replaced by a single value for each column: the mean, median, or mode of that column. One dataframe was created for each method, resulting in a total of five dataframes:

**Feature selection (column deletion)**
In this case, the Temp_EM column is dropped because more than 20% of the values are missing. Remaining rows with NAs are also dropped so that machine learning models can be applied.
```{r, warning=FALSE, echo=T, message=FALSE}

# Function to drop column if quantity of missing values is over the threshold
drop_na_columns <- function(data, threshold) {
  na_counts <- colSums(is.na(data))
  na_proportion <- na_counts / nrow(data)
  data <- data[, na_proportion <= threshold]
  return(data)
}
# Define threshold (e.g., 20% NA allowed)
threshold <- 0.20

# Drop columns based on the NA threshold
dropCol_data <- drop_na_columns(ozone2, threshold) # the column Temp_EM gets dropped
dropCol_data <- data.frame(dropCol_data)
dropCol_data <- na.omit(dropCol_data)

head(dropCol_data)
print(sum(is.na(dropCol_data)))
```

**Listwise deletion (row deletion)**

Create a new dataset where all rows with NAs are deleted.

```{r, warning=FALSE, echo=T, message=FALSE}
# Drop all missing values. Row deletion.
dropNA_data <- na.omit(ozone2)

head(dropNA_data)
print(sum(is.na(dropNA_data)))
```

**Mean imputation**

Create a new dataset where all missing values are replaced with the mean of the column.

```{r, warning=FALSE, echo=T, message=FALSE}
# Function for mean imputation
mean_impute <- function(x) {
  x[is.na(x)] <- mean(x, na.rm = TRUE)
  return(x)
}

imputed_data_mean <- apply(ozone2, 2, mean_impute)
imputed_data_mean <- data.frame(imputed_data_mean)

head(imputed_data_mean)
print(sum(is.na(imputed_data_mean)))
```

**Median imputation**

Create a new dataset where all missing values are replaced with the median of the column.

```{r, warning=FALSE, echo=T, message=FALSE}
# Function for median imputation
median_impute <- function(x) {
  x[is.na(x)] <- median(x, na.rm = TRUE)
  return(x)
}
imputed_data_median <- apply(ozone2, 2, median_impute)
imputed_data_median <- data.frame(imputed_data_median)

head(imputed_data_median)
print(sum(is.na(imputed_data_median)))
```

**Mode imputation**

Create a new dataset where all missing values are replaced with the mode of the column.

```{r, warning=FALSE, echo=T, message=FALSE}
# Function for mode imputation (using the most common value)
mode_impute <- function(x) {
  mode_val <- as.numeric(names(sort(table(x), decreasing = TRUE)[1]))
  x[is.na(x)] <- mode_val
  return(x)
}
imputed_data_mode <- apply(ozone2, 2, mode_impute)
imputed_data_mode <- data.frame(imputed_data_mode)

head(imputed_data_mode)
print(sum(is.na(imputed_data_mode)))
```


#### **Missing Data Imputation Using MICE (Multiple Imputation Method) and missForest (Machine Learning Method)**

Next, the missing data were imputed using MICE and Miss_Forest methods. 

**missForest**
```{r, warning=FALSE, echo=T, message=FALSE, results=FALSE}

library(missForest)

# verbose = If 'TRUE' the user is supplied with additional output between iterations
# xtrue = Complete data matrix
ozone2_mf <- missForest(ozone2, xtrue = ozone2, verbose = TRUE)
# convert back to data frame
ozone2_mf <- as.data.frame(ozone2_mf$ximp)
print(sum(is.na(ozone2_mf)))

## The final results can be accessed directly. The estimated error:
ozone2_mf$OOBerror

## The true imputation error (if available):
ozone2_mf$error
```

**MICE**

```{r, warning=FALSE, echo=T, message=FALSE, results=FALSE}
library(mice)

# Impute missing values using MICE
# pmm = Predictive Mean Matching (suitable for continuous variables like temperature, wind, etc.)
# m = 5: number of imputed datasets to create.
# maxit = 50: max number of iterations
ozone2_mice <- mice(ozone2, method = "pmm", m = 5, maxit = 50)

# extracts the completed datasets from the mice object
ozone2_mice <- complete(ozone2_mice)

# Convert completed data to data frame
ozone2_mice <- as.data.frame(ozone2_mice)

print(sum(is.na(ozone2_mice)))
```

#### **Model-Fitting of Imputed Datasets**

**Make Predictions Using Data Where Missing Values Were Deleted Using Listwise Deletion (Deletion of all missing rows with missing data)**

The listwise deleted dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors (KNN)
* Decision Tree

After models were fit to the training data, predictions were made on the unseen test data. RMSE was then reported for each model. 

Load additional libraries and split the data into training and testing sets

```{r, warning=FALSE, echo=T, message=FALSE}
#Load additional libraries for model fitting
library(caret) # for fitting KNN models
library(e1071)
library(rsample) # for creating validation splits
library(recipes)    # for feature engineering
library(randomForest)
library(rpart)# decision tree
library(tidymodels) 
library(class) 
library(vip) 

# Split the data into training and testing sets
set.seed(123)
data_split_dropNA <- initial_split(dropNA_data, prop = 0.75)
train_dropNA <- training(data_split_dropNA)
test_dropNA <- testing(data_split_dropNA)

# Split data into predictors and target
X <- train_dropNA[, -1]  # Features
y <- train_dropNA$Ozone_reading  # Target

# Function to calculate RMSE
rmse <- function(pred, actual) {
  sqrt(mean((pred - actual)^2))
}
```
**Random Forest**
```{r, warning=FALSE, echo=T, message=FALSE}
# Random forest model
rf_dropNA <- randomForest(Ozone_reading ~ ., data = train_dropNA)
# make predictions
rf_dropNA_pred <- predict(rf_dropNA, newdata = test_dropNA)
# Plot variable importance
varImpPlot(rf_dropNA, main = "Variable Importance Plot for Random Forest Model")

rf_dropNA_rmse <- rmse(rf_dropNA_pred, test_dropNA$Ozone_reading)
cat("Random Forest RMSE:", rf_dropNA_rmse, "\n")
```
**KNN**
```{r, warning=FALSE, echo=T, message=FALSE}
# KNN model
knn_dropNA <- train(Ozone_reading ~ ., data = train_dropNA, method = "knn")
# make predictions
knn_dropNA_pred <- predict(knn_dropNA, newdata = test_dropNA)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")

knn_dropNA_rmse <- rmse(knn_dropNA_pred, test_dropNA$Ozone_reading)
cat("KNN RMSE:", knn_dropNA_rmse, "\n")
```
**Decision Tree**
```{r, warning=FALSE, echo=T, message=FALSE}
# Decision tree model
tree_dropNA <- rpart(Ozone_reading ~ ., data = train_dropNA)
# make predictions
tree_dropNA_pred <- predict(tree_dropNA, newdata = test_dropNA)
# Plot variable importance
var_importance <- varImp(tree_dropNA)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

tree_dropNA_rmse <- rmse(tree_dropNA_pred, test_dropNA$Ozone_reading)
cat("Decision Tree RMSE:", tree_dropNA_rmse, "\n")
```

**Make Predictions Using Data Where Columns with >20% Missing Data Were Deleted (Temp_EM column)**

The deleted column dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors (KNN)
* Decision Tree

After models were fit to the training data, predictions were made on the unseen test data. RMSE was then reported for each model. 

For the column deletion method (feature selection), random forest had the best model fit, with an RMSE of 3.66.

```{r}
# Split the data into training and testing sets
set.seed(123)
data_split_dropCol <- initial_split(dropCol_data, prop = 0.75)
train_dropCol <- training(data_split_dropCol)
test_dropCol <- testing(data_split_dropCol)

# Split data into predictors and target
X <- train_dropCol[, -1]  # Features
y <- train_dropCol$Ozone_reading  # Target
```


**Random Forest**


```{r}
# Random forest model
rf_dropCol <- randomForest(Ozone_reading ~ ., data = train_dropCol)
# make predictions
rf_dropCol_pred <- predict(rf_dropCol, newdata = test_dropCol)
# Plot variable importance
varImpPlot(rf_dropCol, main = "Variable Importance Plot for Random Forest Model")

rf_dropCol_rmse <- rmse(rf_dropCol_pred, test_dropCol$Ozone_reading)
cat("Random Forest RMSE:", rf_dropCol_rmse, "\n")
```
**KNN**
```{r}
# KNN model
knn_dropCol <- train(Ozone_reading ~ ., data = train_dropCol, method = "knn")
# make predictions
knn_dropCol_pred <- predict(knn_dropCol, newdata = test_dropCol)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")

knn_dropCol_rmse <- rmse(knn_dropCol_pred, test_dropCol$Ozone_reading)
cat("KNN RMSE:", knn_dropCol_rmse, "\n")
```
**Decision Tree**
```{r}
# Decision tree model
tree_dropCol <- rpart(Ozone_reading ~ ., data = train_dropCol)
# make predictions
tree_dropCol_pred <- predict(tree_dropCol, newdata = test_dropCol)
# Plot variable importance
var_importance <- varImp(tree_dropCol)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

tree_dropCol_rmse <- rmse(tree_dropCol_pred, test_dropCol$Ozone_reading)
cat("Decision Tree RMSE:", tree_dropCol_rmse, "\n")
```

**Make Predictions Using Data Where Missing Values were Imputed using the Mean**

The mean imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors (KNN)
* Decision Tree

After models were fit to the training data, predictions were made on the unseen test data. RMSE was then reported for each model. 

For the mean imputation method, random forest had the best model fit, with an RMSE of 4.90.

```{r}
# Split the data into training and testing sets
set.seed(123)
data_split_mean <- initial_split(imputed_data_mean, prop = 0.75)
train_mean <- training(data_split_mean)
test_mean <- testing(data_split_mean)

# Split data into predictors and target
X <- train_mean[, -1]  # Features
y <- train_mean$Ozone_reading  # Target

# Random forest model
rf_mean <- randomForest(Ozone_reading ~ ., data = train_mean)
# make predictions
rf_mean_pred <- predict(rf_mean, newdata = test_mean)
# Plot variable importance
varImpPlot(rf_mean, main = "Variable Importance Plot for Random Forest Model")

rf_mean_rmse <- rmse(rf_mean_pred, test_mean$Ozone_reading)
cat("Random Forest RMSE:", rf_mean_rmse, "\n")
```

**KNN**
```{r}
# KNN model
knn_mean <- train(Ozone_reading ~ ., data = train_mean, method = "knn")
# make predictions
knn_mean_pred <- predict(knn_mean, newdata = test_mean)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")

knn_mean_rmse <- rmse(knn_mean_pred, test_mean$Ozone_reading)
cat("KNN RMSE:", knn_mean_rmse, "\n")
```

**Decision Tree**
```{r}
# Decision tree model
tree_mean <- rpart(Ozone_reading ~ ., data = train_mean)
# make predictions
tree_mean_pred <- predict(tree_mean, newdata = test_mean)
# Plot variable importance
var_importance <- varImp(tree_mean)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

tree_mean_rmse <- rmse(tree_mean_pred, test_mean$Ozone_reading)
cat("Decision Tree RMSE:", tree_mean_rmse, "\n")
```

**Make Predictions Using Data Where Missing Values were Imputed using the Median**

The mean imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors (KNN)
* Decision Tree

After models were fit to the training data, predictions were made on the unseen test data. RMSE was then reported for each model. 

For the mean imputation method, random forest had the best model fit, with an RMSE of 5.07.

```{r}
# Split the data into training and testing sets
set.seed(123)
data_split_med <- initial_split(imputed_data_median, prop = 0.75)
train_med <- training(data_split_med)
test_med <- testing(data_split_med)
```

**Random Forest**
```{r}
# Random forest model
rf_med <- randomForest(Ozone_reading ~ ., data = train_med)
rf_med_pred <- predict(rf_med, newdata = test_med)
# Plot variable importance
varImpPlot(rf_med, main = "Variable Importance Plot for Random Forest Model")

rf_med_rmse <- rmse(rf_med_pred, test_med$Ozone_reading)
cat("Random Forest RMSE:", rf_med_rmse, "\n")
```

**KNN**
```{r}
# KNN model
knn_med <- train(Ozone_reading ~ ., data = train_med, method = "knn")
knn_med_pred <- predict(knn_med, newdata = test_med)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")

knn_med_rmse <- rmse(knn_med_pred, test_med$Ozone_reading)
cat("KNN RMSE:", knn_med_rmse, "\n")
```

**Decision Tree**
```{r}
# Decision tree model
tree_med <- rpart(Ozone_reading ~ ., data = train_med)
tree_med_pred <- predict(tree_med, newdata = test_med)
# Plot variable importance
var_importance <- varImp(tree_med)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

tree_med_rmse <- rmse(tree_med_pred, test_med$Ozone_reading)
cat("Decision Tree RMSE:", tree_med_rmse, "\n")
```

**Make Predictions Using Data Where Missing Values were Imputed using the Mode**

The mean imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors (KNN)
* Decision Tree

After models were fit to the training data, predictions were made on the unseen test data. RMSE was then reported for each model. 

For the mode imputation method, random forest had the best model fit, with an RMSE of 5.40.

```{r}
# Split the data into training and testing sets
set.seed(123)
data_split_mode <- initial_split(imputed_data_mode, prop = 0.75)
train_mode <- training(data_split_mode)
test_mode <- testing(data_split_mode)
```

**Random Forest**
```{r}
# Random forest model
rf_mode <- randomForest(Ozone_reading ~ ., data = train_mode)
rf_mode_pred <- predict(rf_mode, newdata = test_mode)
# Plot variable importance
varImpPlot(rf_mode, main = "Variable Importance Plot for Random Forest Model")

rf_mode_rmse <- rmse(rf_mode_pred, test_mode$Ozone_reading)
cat("Random Forest RMSE:", rf_mode_rmse, "\n")
```

**KNN**
```{r}
# KNN model
knn_mode <- train(Ozone_reading ~ ., data = train_mode, method = "knn")
knn_mode_pred <- predict(knn_mode, newdata = test_mode)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")

knn_mode_rmse <- rmse(knn_mode_pred, test_mode$Ozone_reading)
cat("KNN RMSE:", knn_mode_rmse, "\n")
```

**Decision Tree**
```{r}
# Decision tree model
tree_mode <- rpart(Ozone_reading ~ ., data = train_mode)
tree_mode_pred <- predict(tree_mode, newdata = test_mode)
# Plot variable importance
var_importance <- varImp(tree_mode)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

tree_mode_rmse <- rmse(tree_mode_pred, test_mode$Ozone_reading)
cat("Decision Tree RMSE:", tree_mode_rmse, "\n")
```

#### **Make Predictions using data where missing values were imputed with complex methods:**

**Make Predictions Using Data Where Missing Values were Imputed using missForest Method**

The missForest imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors (KNN)
* Decision Tree

After models were fit to the training data, predictions were made on the unseen test data. RMSE was then reported for each model. 

For the missForest imputation method, random forest had the best model fit, with an RMSE of 4.46.

```{r}
# Split the data into training and testing sets
set.seed(123)
data_split_miss <- initial_split(ozone2_mf, prop = 0.75)
train_miss <- training(data_split_miss)
test_miss <- testing(data_split_miss)
```

**Random Forest**
```{r}
# Random forest model
rf_miss <- randomForest(Ozone_reading ~ ., data = train_miss)
rf_miss_pred <- predict(rf_miss, newdata = test_miss)
# Plot variable importance
varImpPlot(rf_miss, main = "Variable Importance Plot for Random Forest Model")

rf_miss_rmse <- rmse(rf_miss_pred, test_miss$Ozone_reading)
cat("Random Forest RMSE:", rf_miss_rmse, "\n")
```

**KNN**
```{r}
# KNN model
knn_miss <- train(Ozone_reading ~ ., data = train_miss, method = "knn")
knn_miss_pred <- predict(knn_miss, newdata = test_miss)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")

knn_miss_rmse <- rmse(knn_miss_pred, test_miss$Ozone_reading)
cat("KNN RMSE:", knn_miss_rmse, "\n")
```

**Decision Tree**
```{r}
# Decision tree model
tree_miss <- rpart(Ozone_reading ~ ., data = train_miss)
tree_miss_pred <- predict(tree_miss, newdata = test_miss)
# Plot variable importance
var_importance <- varImp(tree_miss)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

tree_miss_rmse <- rmse(tree_miss_pred, test_miss$Ozone_reading)
cat("Decision Tree RMSE:", tree_miss_rmse, "\n")
```

**Make Predictions Using Data Where Missing Values were Imputed using MICE Method**

The MICE imputed dataset was split into testing and training datasets using a split ratio of 0.75. Models were then fit using the following algorithms:

* Random Forest
* K-Nearest Neighbors (KNN)
* Decision Tree

After models were fit to the training data, predictions were made on the unseen test data. RMSE was then reported for each model. 

For the MICE imputation method, random forest had the best model fit, with an RMSE of 4.70.


```{r}
# Split the data into training and testing sets
set.seed(123)
data_split_mice <- initial_split(ozone2_mice, prop = 0.75)
train_mice <- training(data_split_mice)
test_mice <- testing(data_split_mice)
```

**Random Forest**
```{r}
# Random forest model
rf_mice <- randomForest(Ozone_reading ~ ., data = train_mice)
rf_mice_pred <- predict(rf_mice, newdata = test_mice)
# Plot variable importance
varImpPlot(rf_mice, main = "Variable Importance Plot for Random Forest Model")

rf_mice_rmse <- rmse(rf_mice_pred, test_mice$Ozone_reading)
cat("Random Forest RMSE:", rf_mice_rmse, "\n")
```

**KNN**
```{r}
# KNN model
knn_mice <- train(Ozone_reading ~ ., data = train_mice, method = "knn")
knn_mice_pred <- predict(knn_mice, newdata = test_mice)
# Plot variable importance
feature_importance <- table(y) / length(y)
barplot(feature_importance, main = "Feature Importance for KNN", xlab = "Feature", ylab = "Importance")

knn_mice_rmse <- rmse(knn_mice_pred, test_mice$Ozone_reading)
cat("KNN RMSE:", knn_mice_rmse, "\n")
```

**Decision Tree**
```{r}
# Decision tree model
tree_mice <- rpart(Ozone_reading ~ ., data = train_mice)
tree_mice_pred <- predict(tree_mice, newdata = test_mice)
# Plot variable importance
var_importance <- varImp(tree_mice)
barplot(var_importance$Overall, main = "Variable Importance for Decision Tree", xlab = "Variable", ylab = "Importance")

tree_mice_rmse <- rmse(tree_mice_pred, test_mice$Ozone_reading)
cat("Decision Tree RMSE:", tree_mice_rmse, "\n")
```

#### **Summarize Model Performance for Each Imputation Methodology**

The RMSE for each model and imputation method combination was summarized into a data frame. The results are shown below. The best model fit (lowest RMSE) was obtained when using feature selection (column deletion) for imputation of missing data and the random forest algorithm for model training with the resulting dataset. Mean imputation with the Decision Tree model fitting was the second best combination, followed by mode imputation with Random Forest.

```{r, warning=FALSE, echo=T, message=FALSE}
models <- c('RandomForest', 'KNN', 'DecisionTree')
scores <- c(rf_dropCol_rmse, knn_dropCol_rmse, tree_dropCol_rmse,
            rf_dropNA_rmse, knn_dropNA_rmse, tree_dropNA_rmse,
            rf_mean_rmse, knn_mean_rmse, tree_mean_rmse,
            rf_med_rmse, knn_med_rmse, tree_med_rmse,
            rf_mode_rmse, knn_mode_rmse, tree_mode_rmse,
            rf_miss_rmse, knn_miss_rmse, tree_miss_rmse,
            rf_mice_rmse, knn_mice_rmse, tree_mice_rmse
)
ImpMethod <- c('DropCol','DropNA','Mean', 'Median', 'Mode','missForest','MICE')

# Create dataframe
rmse_df <- data.frame(Model = models, ImpMethod=ImpMethod,RMSE = scores)
print(rmse_df[order(rmse_df$RMSE), ])
```


# Conclusions

In summary, maintaining the integrity and dependability of data analysis procedures depends on the management of missing data. This work demonstrates various methodologies that can be used to handle missing data, including listwise and feature selection deletion methods, machine learning-based algorithms like missForest, single imputation techniques such as mean, mode, median imputation, and multiple imputation using MICE. The dataset "Ozone", from the mlbench package in R was used to demonstrate the techniques for either deleting or imputing missing data. Statistical tests and visualization techniques to help classify data as MCAR, MAR, and NMAR were also demonstrated. With respect to the "Ozone" dataset, deletion of the column Temp_EM, which contains ~38% missing data, was found to be the most effective method for handling missing data. This was demonstrated through machine learning models trained to datasets where missing data were handled using the various techniques described above. A total of seven datasets were created, and each dataset was trained and tested with KNN, decision tree, and random forest algorithms. The random forest model in combination with feature selection for handling missing data resulted in the lowest RMSE with respect to the test (unseen) dataset. This may have been the best result in this instance because this data appear to be MCAR based on statistical testing. It is best practice to test a variety of different methods, as was performed in this work, and predefine success criteria when handling missing data. To provide reliable and accurate results from data analysis, the imputation method selected should ultimately be in line with the unique features of the dataset and the analytical objectives. 


# References
